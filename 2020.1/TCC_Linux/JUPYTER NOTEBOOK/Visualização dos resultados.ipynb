{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from trinta_testes_validacao_cruzada import TrintaTestes\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import itertools\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções para plotagem da matriz de confusão e dos atributos mais importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções para plotagem da matriz de confusão\n",
    "\n",
    "def view_confusion_matrix(conf_matrix, classes=None,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    \n",
    "    accuracy = np.trace(conf_matrix) / np.sum(conf_matrix).astype('float')\n",
    "    misclass = 1 - accuracy\n",
    "    if normalize:\n",
    "        conf_matrix = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "    plt.imshow(conf_matrix, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    if classes:\n",
    "        tick_marks = np.arange(len(classes))\n",
    "        plt.xticks(tick_marks, classes, rotation=45)\n",
    "        plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else '.0f'\n",
    "    thresh = conf_matrix.max() / 2.\n",
    "    for i, j in itertools.product(range(conf_matrix.shape[0]), range(conf_matrix.shape[1])):\n",
    "        plt.text(j, i, format(conf_matrix[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if conf_matrix[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    plt.cla()\n",
    "    plt.close()\n",
    "\n",
    "def plotConfusionMatrix(cnf_matrix, classes_):\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    # para habilitar a configuração do tamanho da imagem a ser plotada \n",
    "    matplotlib.style.use('default')\n",
    "    \n",
    "    # tamanho da imagem a ser plotada\n",
    "    plt.figure(figsize=(6,4))\n",
    "        \n",
    "    # Plot non-normalized confusion matrix\n",
    "    if classes_:\n",
    "        view_confusion_matrix(cnf_matrix, classes=classes_,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "    else:\n",
    "        view_confusion_matrix(cnf_matrix,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "    \n",
    "    # tamanho da imagem a ser plotada\n",
    "    plt.figure(figsize=(6,4))\n",
    "    \n",
    "    # Plot normalized confusion matrix\n",
    "    if classes_:\n",
    "        view_confusion_matrix(cnf_matrix, classes=classes_, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "    else:\n",
    "        view_confusion_matrix(cnf_matrix, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "        \n",
    "\n",
    "# função para verificação dos atributos mais importante para árvore de decisão e random forest\n",
    "\n",
    "def importance(importancias):\n",
    "    \n",
    "    # juntando os dataframes pertencentes à lista passada como parâmetro em um só dataframe\n",
    "    importances = pd.concat(importancias, axis=0, join='inner')\n",
    "    \n",
    "    # eliminando duplicidade de atributos e unificando por média\n",
    "    importances = importances.groupby(importances.index).agg('mean')\n",
    "    \n",
    "    # ordenando por importância\n",
    "    importances = importances.sort_values('importance', ascending = False)\n",
    "    display(importances)\n",
    "\n",
    "    # imprimindo valores com nome dos atributos, em ordem e através de gráfico em barras\n",
    "    importances.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separação da base em previsores e classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = pd.read_csv('dados_meio_tempo_com_odds.csv').drop(['Unnamed: 0'], axis=1).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "previsores = base.iloc[:, 0:35].values\n",
    "classe = base.iloc[:, 35].values\n",
    "\n",
    "classes_alvo = ['Visitante', 'Empate', 'Mandante']\n",
    "\n",
    "# apenas para visualizar em forma de dataframe\n",
    "classe_df = pd.DataFrame(classe)\n",
    "previsores_df = pd.DataFrame(previsores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformando variáveis categóricas em numéricas usando o LabelEncoder\n",
    "\n",
    "# para previsores\n",
    "labelencoder_X = LabelEncoder()\n",
    "previsores[:, 0] = labelencoder_X.fit_transform(previsores[:, 0])\n",
    "previsores[:, 1] = labelencoder_X.fit_transform(previsores[:, 1])\n",
    "previsores[:, 31] = labelencoder_X.fit_transform(previsores[:, 31])\n",
    "\n",
    "\n",
    "# para classe LabelEncoder não costuma ser necessário\n",
    "'''labelencoder_classe = LabelEncoder()\n",
    "classe = labelencoder_classe.fit_transform(classe)'''\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformando variáveis categóricas em numéricas e tirando o peso dos valores após a transformação\n",
    "# através do OneHotEncoder\n",
    "\n",
    "column_tranformer = ColumnTransformer([('one_hot_encoder', OneHotEncoder(), [0, 1, 31])],remainder='passthrough')\n",
    "previsores = column_tranformer.fit_transform(previsores)\n",
    "\n",
    "# apenas para visualizar em forma de dataframe\n",
    "previsores_onehotencoder_df = pd.DataFrame(previsores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fazendo escalonamento das variáveis (normalização) através do StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "previsores = scaler.fit_transform(previsores)\n",
    "\n",
    "# apenas para visualizar em forma de dataframe\n",
    "previsores_StandardScaler_df = pd.DataFrame(previsores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fazendo chamada para algoritmos de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chamando método para fazer treinamento e classificação com trinta testes\n",
    "# e validação cruzada usando StratifiedKFold\n",
    "# Decision Tree\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classificador = DecisionTreeClassifier()\n",
    "decision_tree = TrintaTestes(classificador, previsores, classe, columns_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(decision_tree.acuracia().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance(decision_tree.importances())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chamando método para fazer treinamento e classificação com trinta testes\n",
    "# e validação cruzada usando StratifiedKFold\n",
    "# Gaussian Naive Bayes\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "classificador = GaussianNB()\n",
    "naive_bayes = TrintaTestes(classificador, previsores, classe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(naive_bayes.acuracia().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chamando método para fazer treinamento e classificação com trinta testes\n",
    "# e validação cruzada usando StratifiedKFold\n",
    "# ODDS\n",
    "\n",
    "from odds import OddsClassifier\n",
    "\n",
    "classificador = OddsClassifier() \n",
    "odds = TrintaTestes(classificador, previsores, classe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(odds.importances())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(odds.acuracia().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotConfusionMatrix(odds.matrizConfusao(), classes_alvo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chamando método para fazer treinamento e classificação com trinta testes\n",
    "# e validação cruzada usando StratifiedKFold\n",
    "# KNN\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classificador = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p = 2)\n",
    "knn = TrintaTestes(classificador, previsores, classe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(knn.acuracia().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chamando método para fazer treinamento e classificação com trinta testes\n",
    "# e validação cruzada usando StratifiedKFold\n",
    "# RNA\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "classificador = MLPClassifier(verbose = True, max_iter = 1000,\n",
    "                      tol = 0.000010, solver='adam',\n",
    "                      hidden_layer_sizes=(100), activation = 'relu',\n",
    "                      batch_size=200, learning_rate_init=0.001)\n",
    "rna = TrintaTestes(classificador, previsores, classe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chamando método para fazer treinamento e classificação com trinta testes\n",
    "# e validação cruzada usando StratifiedKFold\n",
    "# SVM\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "classificador = SVC(kernel = 'rbf', random_state = 1, C = 2.0)\n",
    "svm = TrintaTestes(classificador, previsores, classe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(svm.acuracia().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chamando método para fazer treinamento e classificação com trinta testes\n",
    "# e validação cruzada usando StratifiedKFold\n",
    "# Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "columns_ = base.iloc[:, 0:35].columns\n",
    "classificador = RandomForestClassifier(n_estimators=40, criterion='entropy', random_state=0)\n",
    "random_forest = TrintaTestes(classificador, previsores, classe, columns_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance(random_forest.importances())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(random_forest.acuracia().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lista com os resultados de cada algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista com os resultados dos algoritmos para o boxplot - trazida por chamada anteriormente\n",
    "# para não ter que executar todo o código sempre\n",
    "\n",
    "random_forest_list = [0.6440528058556989, 0.6353738236319275, 0.640083652840711, 0.6407764029278494, 0.6433426280934122, 0.6420834785639595, 0.6552631578947368, 0.6334349947716975, 0.6346985012199372, 0.638027187173231, 0.6400400836528407, 0.6393386197281282, 0.6426324503311258, 0.6334872777971419, 0.6452553154409202, 0.6354217497385848, 0.6261327988846288, 0.6346897873823633, 0.6387460787730916, 0.6261937957476473, 0.6346287905193447, 0.6399616591146742, 0.635439177413733, 0.6406326246078773, 0.64394823980481, 0.6354435343325201, 0.6367506099686302, 0.642022481700941, 0.6394170442662949, 0.6414212269083304]\n",
    "odds_list = [0.554247995817358, 0.55411293133496, 0.5542305681422098, 0.554139072847682, 0.5541303590101081, 0.5541652143604043, 0.5541085744161729, 0.5541521436040433, 0.554126002091321, 0.5541782851167654, 0.5541477866852562, 0.554139072847682, 0.554121645172534, 0.5542262112234229, 0.5541565005228303, 0.5541434297664691, 0.5541521436040433, 0.5541434297664691, 0.5542523527361449, 0.5542044266294877, 0.5540867898222377, 0.5540955036598118, 0.554130359010108, 0.5541565005228303, 0.5541565005228303, 0.5541521436040433, 0.5542000697107006, 0.5541957127919136, 0.5541957127919136, 0.5541957127919136]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chamando os resultados e armazenando em lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trazendo por chamada a lista com os resultados dos algoritmos para o boxplot\n",
    "\n",
    "random_forest_list = random_forest.acuracia()\n",
    "odds_list = odds.acuracia()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Juntando todas as listas em um único dataframe para exibir com o boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# juntando todas as listas em um só dataframe para plotar com o boxplot\n",
    "\n",
    "random_forest_df = pd.DataFrame(random_forest_list, columns=['Random Forest'])\n",
    "#svm_df = pd.DataFrame(svm.acuracia()).rename(columns={0:'SVM'})\n",
    "#knn_df = pd.DataFrame(knn.acuracia()).rename(columns={0:'KNN'})\n",
    "#naive_bayes_df = pd.DataFrame(naive_bayes.acuracia()).rename(columns={0:'Naive Bayes'})\n",
    "#decision_tree_df = pd.DataFrame(decision_tree.acuracia()).rename(columns={0:'Árvore de Decisão'})\n",
    "odds_df = pd.DataFrame(odds_list, columns=['ODDS'])\n",
    "# juntando todos os dataframes acima em um só \n",
    "resultados_df = pd.concat([random_forest_df,odds_df], axis=1, join='inner')\n",
    "\n",
    "display(resultados_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplot com os resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,5))\n",
    "resultados_df.boxplot(column=['Random Forest','ODDS'])\n",
    "plt.title('Algoritmos de Machine Learning')\n",
    "plt.ylabel('Acurácia', fontsize=12, color='black')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
