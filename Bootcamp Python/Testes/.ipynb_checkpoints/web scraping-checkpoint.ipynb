{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "src = os.path.join(os.path.dirname(os.getcwd()))\n",
    "sys.path.append(src)\n",
    "\n",
    "from src import utils\n",
    "\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# método get - recebendo dados da net de forma automática\n",
    "\n",
    "import requests \n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O MÉTODO ACIMA É BEM SIMPLES, NÃO CHEGUEI A IMPLEMENTAR MAS SE QUISER VER\n",
    "# SÓ ABRIR O GMAIL E PESQUISAR POR \"ROBÔ WEB\" E VER OS LINKS. UM DELES ENSINA A PEGAR DADOS DA WEB\n",
    "# USANDO O IMPORT REQUESTS E O CÓDIGO ACIMA ALÉM DE MAIS UM POUCO DE CÓDIGO.\n",
    "# MAS PARA PEGAR DADOS DA WEB ELE TAMBÉM ENSINOU UMA MANEIRA MAIS ROBUSTA QUE ESTÁ EXEMPLIFICADA \n",
    "# ABAIXO, USANDO O PACOTE BEAUTIFULSOUP. PREFERI IMPLEMENTAR DESTA ÚLTIMA FORMA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# método post - mandando dados pela net de forma automática\n",
    "\n",
    "import requests\n",
    "import re\n",
    "\n",
    "session = requests.Session()\n",
    "\n",
    "url = 'http://testing-ground.scraping.pro/login?mode=login'\n",
    "data = {'pwd': '12345', 'usr': 'admin'}\n",
    "\n",
    "headers = {'User-Agent': ''}\n",
    "session.get('http://testing-ground.scraping.pro/login')\n",
    "response = session.post(url, data=data, headers=headers)\n",
    "re.findall('WELCOME', response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "url1 = 'https://pt.wikipedia.org/wiki/Campeonato_Brasileiro_de_Futebol_de_2019_-_S%C3%A9rie_A'\n",
    "resposta = requests.get(url1)\n",
    "\n",
    "soup = BeautifulSoup(resposta.text, 'html.parser')\n",
    "tabela = soup.find_all('table')\n",
    "print(len(tabela))\n",
    "print(tabela[0])\n",
    "print(tabela[21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabelas = pd.read_html(str(soup), header = 0)\n",
    "len(tabelas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = tabelas[3]\n",
    "dados.head(20) # esse 20 é o número de amostras (linhas) que eu quero\n",
    "               # nesse caso 20 são todas as linhas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "url = 'https://pt.wikipedia.org/wiki/Ubuntu'\n",
    "resposta = requests.get(url)\n",
    "\n",
    "soup = bs(resposta.text, 'html.parser')\n",
    "tabela = soup.find_all('p')\n",
    "print(tabela)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "url = 'https://future.pinnacle.com/en'\n",
    "resposta = requests.get(url)\n",
    "with open('pin.html', 'wb') as arq:\n",
    "    arq.write(resposta.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "url = 'https://pt.wikipedia.org/wiki/Ubuntu'\n",
    "resposta = requests.get(url)\n",
    "\n",
    "page = bs(resposta.text, 'html.parser')\n",
    "conteudo = page.find_all('a')\n",
    "# print(conteudo, '\\n') aqui é o conteúdo da linha anterior da tag \"a\"\n",
    "print(conteudo[4], '\\n') # esse conteúdo já vem de um \"find (find_all no caso) e posso especificar com \"[4]\"\n",
    "print(conteudo[4].find('abbr'), '\\n') # eu posso ir de um \"find\" e usar \"[]\" e dá outro \"find\" e usar \"[]\" novamente\n",
    "                                # e ir entrando mais na página e especificando mais ainda o que eu quero\n",
    "\n",
    "print(conteudo[4].find('abbr').text, '\\n') # nesses prints qnd cheguei onde queria, ainda mandei exibir só os textos\n",
    "print(page.find_all('p')[3].text)\n",
    "print(page.find('body').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "# do requests temos os métodos, get, post, put, delete. Para ver como funciona pesquisar\n",
    "# se eu só vou usar o método get do requests, eu poderia apenas fazer:\n",
    "# from requests import get\n",
    "# e no lugar do códgigo abaixo: resposta = requests.get(url)\n",
    "# eu faria apenas: resposta = get(url)\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "url = 'https://pt.wikipedia.org/wiki/Ubuntu'\n",
    "resposta = requests.get(url)\n",
    "print(f'A reposta do servidor é -> {resposta} \\n\\n')\n",
    "print(f'O código da reposta do servidor é -> {resposta.status_code} \\n\\n')\n",
    "print(f'O cabeçalho do servidor é -> {resposta.headers} \\n\\n')\n",
    "print(f'Os cookies do servidor é -> {resposta.cookies} \\n\\n')\n",
    "print(f'O texto do servidor que vamos usar com o BeautifulSoup é -> {resposta.text} \\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = bs(resposta.text, 'html.parser')\n",
    "\n",
    "# a tag class que está dentro de table tbm pode ser especificada assim: \n",
    "#conteudo = page.find_all('table', class_='cquote')\n",
    "conteudo = page.find('table', {'class': 'cquote'})\n",
    "print('Aqui começa o uso do BeautifulSoup \\n\\n')\n",
    "print(f'print direto no objeto page que recebe o BeautifulSoup {page} \\n\\n')\n",
    "print('Usando o \"find\" e o \"text\" \\n')\n",
    "print(conteudo.text)\n",
    "\n",
    "# se usássemos o \"find_all\" então para imprimirmos como texto, deveríamos dizer a posição\n",
    "# do elemento mesmo que só tivesse 1. Neste caso usaríamos a posição \"[0]\" que é a primeira posição\n",
    "# e como só temos 1 elemento, ele está na primeira posição. Se tivéssemos mais, faríamos \"[1]\" \"[2]\" e assim\n",
    "# por diante. Veja o mesmo código usando o \"find_all\" e \"text\"\n",
    "\n",
    "print('Agora usando o \"find_all\" e o \"text\" \\n')\n",
    "conteudo = page.find_all('table', {'class': 'cquote'})\n",
    "print(conteudo[0].text)\n",
    "\n",
    "# temos o get tbm para pegar atributos de uma tag assim como outros métodos do BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# como essa página usa javascript, não funciona só com o requests\n",
    "# nem importando o \"time\" e dando um sleep para carregar a página. Já testei \n",
    "# e pra testar novamente é só dá descomentar as duas linhas de códigos\n",
    "# comentadas abaixo\n",
    "\n",
    "# import time\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "url = 'https://future.pinnacle.com/en/'\n",
    "resposta = get(url)\n",
    "# time.sleep(20)\n",
    "page = bs(resposta.text, 'html.parser')\n",
    "print(page.find_all('span')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui mesmo a página usando javascript conseguimos fazer web scraping \n",
    "# para isso usamos o selenium\n",
    "\n",
    "# Aqui o firefox abre quando começar a executar o selenium\n",
    "# serve como depuração tbm pra ver se está respondendo como deveria\n",
    "\n",
    "import time\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium import webdriver\n",
    "\n",
    "url = 'https://future.pinnacle.com/en/'\n",
    "driver = webdriver.Firefox()\n",
    "driver.get(url)\n",
    "time.sleep(15)\n",
    "html = driver.execute_script(\"return document.documentElement.outerHTML\")\n",
    "page_bs = bs(html, 'html.parser')\n",
    "\n",
    "erro_1 = 0\n",
    "erro_2 = 0\n",
    "\n",
    "try:\n",
    "    tam_ao_vivo = len(page_bs.find('div', {'data-test-id':'LiveContainer'}).find_all('span', {'class':'_V4AXE'}))\n",
    "    ao_vivo = page_bs.find('div', {'data-test-id':'LiveContainer'}).find_all('span', {'class':'_V4AXE'})\n",
    "except:\n",
    "    erro_1 = 1\n",
    "    \n",
    "try:\n",
    "    tam_destaques = len(page_bs.find('div',{'data-test-id':'Highlights-Container'}).find_all('span', {'class':'_V4AXE'}))\n",
    "    destaques = page_bs.find('div',{'data-test-id':'Highlights-Container'}).find_all('span', {'class':'_V4AXE'})\n",
    "except:\n",
    "    erro_2 = 1\n",
    "\n",
    "if erro_1 == 0:\n",
    "    print('Ao vivo\\n')\n",
    "    for i in range(tam_ao_vivo):\n",
    "        print(ao_vivo[i].text)\n",
    "\n",
    "if erro_2 == 0:\n",
    "    print('\\nDestaques\\n')\n",
    "    for i in range(tam_destaques): \n",
    "        print(destaques[i].text)                                                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium import webdriver\n",
    "\n",
    "url = 'https://www.betfair.com/exchange/plus/football/inplay/'\n",
    "driver = webdriver.Firefox()\n",
    "driver.get(url)\n",
    "time.sleep(15)\n",
    "html = driver.execute_script(\"return document.documentElement.outerHTML\")\n",
    "page = bs(html, 'html.parser')\n",
    "tamanho = len(page.find_all(class_='name'))\n",
    "for i in range(tamanho):\n",
    "    times = page.find_all(class_='name')\n",
    "    print(times[i].text)\n",
    "driver.quit() # aqui ao final fecha o navegador que estava aberto e visível"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para usar o selenium com firefox invísivel use o código abaixo\n",
    "\n",
    "from selenium import webdriver\n",
    "\n",
    "# local onde se encontra o instalador do geckdriver\n",
    "geckodriver = '/home/andre/Downloads/geckodriver'\n",
    "\n",
    "driver = webdriver.FirefoxOptions()\n",
    "driver.add_argument('-headless')\n",
    "\n",
    "driver = webdriver.Firefox(executable_path=geckodriver, options=driver)\n",
    "\n",
    "driver.get('https://www.betfair.com/exchange/plus/football/inplay')\n",
    "time.sleep(15)\n",
    "driver.save_screenshot('/home/andre/Downloads/andre.png')\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# navegador invisível\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "geckodriver = '/home/andre/Downloads/geckodriver'\n",
    "driver = webdriver.FirefoxOptions()\n",
    "driver.add_argument('-headless')\n",
    "driver = webdriver.Firefox(executable_path=geckodriver, options=driver)\n",
    "driver.get('https://www.betfair.com/exchange/plus/football/inplay')\n",
    "time.sleep(15)\n",
    "\n",
    "html = driver.execute_script(\"return document.documentElement.outerHTML\")\n",
    "page = bs(html, 'html.parser')\n",
    "tamanho = len(page.find_all(class_='name'))\n",
    "for i in range(tamanho):\n",
    "    times = page.find_all(class_='name')\n",
    "    print(times[i].text)\n",
    "driver.quit() # fecha o navegador que estava aberto porém invisível"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baixando a página HTLM da pinnacle\n",
    "# posso fazer isso mostrando o navegador ou não\n",
    "# neste caso optei por usar navegação invisível\n",
    "\n",
    "import time\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium import webdriver\n",
    "\n",
    "gecko = '/home/andre/Downloads/geckodriver'\n",
    "driver = webdriver.FirefoxOptions()\n",
    "driver.add_argument('-headless')\n",
    "driver = webdriver.Firefox(executable_path=gecko, options=driver)\n",
    "\n",
    "url = 'https://future.pinnacle.com/en'\n",
    "driver.get(url)\n",
    "time.sleep(15)\n",
    "\n",
    "html = driver.execute_script(\"return document.documentElement.outerHTML\")\n",
    "page = bs(html, 'html.parser')\n",
    "\n",
    "with open('pinnacle.html', 'w') as arq:\n",
    "    arq.write(html) # aqui tbm pode passar como parâmetro \"page.text\"\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baixando a página HTLM da betfair\n",
    "# posso fazer isso mostrando o navegador ou não\n",
    "# neste caso optei por usar navegação invisível\n",
    "\n",
    "import time\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium import webdriver\n",
    "\n",
    "gecko = '/home/andre/Downloads/geckodriver'\n",
    "driver = webdriver.FirefoxOptions()\n",
    "driver.add_argument('-headless')\n",
    "driver = webdriver.Firefox(executable_path=gecko, options=driver)\n",
    "\n",
    "url = 'https://www.betfair.com/exchange/plus/football/inplay/'\n",
    "driver.get(url)\n",
    "time.sleep(15)\n",
    "\n",
    "html = driver.execute_script(\"return document.documentElement.outerHTML\")\n",
    "page = bs(html, 'html.parser')\n",
    "\n",
    "with open('betfair.html', 'w') as arq:\n",
    "    arq.write(html) # aqui tbm pode passar como parâmetro \"page.text\"\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui mesmo a página usando javascript conseguimos fazer web scraping \n",
    "# para isso usamos o selenium\n",
    "\n",
    "# Aqui o firefox abre quando começar a executar o selenium\n",
    "# serve como depuração tbm pra ver se está respondendo como deveria\n",
    "\n",
    "import time\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium import webdriver   \n",
    "\n",
    "url = 'https://www.betfair.com/exchange/plus/football/inplay/'\n",
    "driver = webdriver.Firefox()\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "\n",
    "# a linha abaixo clica no menu dropdown e a próxima clica em umas das opções que \n",
    "# aparecem após o primeiro clique\n",
    "driver.find_element_by_class_name('group-by-filter').click()\n",
    "driver.find_element_by_css_selector('.expanded > div:nth-child(3) > bf-option:nth-child(2) > span:nth-child(1)').click()\n",
    "\n",
    "time.sleep(15)\n",
    "html = driver.execute_script(\"return document.documentElement.outerHTML\")\n",
    "page_selenium = bs(html, 'html.parser')\n",
    "\n",
    "erro_1 = 0\n",
    "erro_2 = 0\n",
    "\n",
    "try:\n",
    "    tam_ao_vivo = len(page_selenium.find_all('tbody')[1].find_all(class_='name'))\n",
    "    ao_vivo = page_selenium.find_all('tbody')[1].find_all(class_='name')\n",
    "except:\n",
    "    erro_1 = 1\n",
    "    \n",
    "try:\n",
    "    tam_a_seguir = len(page_selenium.find_all('tbody')[2].find_all(class_='name'))\n",
    "    a_seguir = page_selenium.find_all('tbody')[2].find_all(class_='name')\n",
    "except:\n",
    "    erro_2 = 1\n",
    "\n",
    "if erro_1 == 0:\n",
    "    print('Ao vivo\\n')\n",
    "    for i in range(tam_ao_vivo):    \n",
    "        print(ao_vivo[i].text)\n",
    "\n",
    "if erro_2 == 0:\n",
    "    print('\\nA seguir\\n')\n",
    "    for i in range(tam_a_seguir):\n",
    "        print(a_seguir[i].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui mesmo a página usando javascript conseguimos fazer web scraping \n",
    "# para isso usamos o selenium\n",
    "# Aqui não abrimos o firefox\n",
    "\n",
    "import time\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium import webdriver \n",
    "\n",
    "gecko = '/home/andre/Downloads/geckodriver'\n",
    "driver = webdriver.FirefoxOptions()\n",
    "driver.add_argument('-headless')\n",
    "driver = webdriver.Firefox(executable_path=gecko, options=driver)\n",
    "\n",
    "url = 'https://www.betfair.com/exchange/plus/football/inplay/'\n",
    "driver.get(url)\n",
    "time.sleep(2) # tempo para que o menu seja carregado e possa ser clicado\n",
    "\n",
    "# a linha abaixo clica no menu dropdown e a próxima clica em umas das opções que \n",
    "# aparecem após o primeiro clique\n",
    "driver.find_element_by_class_name('group-by-filter').click() \n",
    "driver.find_element_by_css_selector('.expanded > div:nth-child(3) > bf-option:nth-child(2) > span:nth-child(1)').click()\n",
    "\n",
    "# tempo para processamento do javascript da página\n",
    "time.sleep(15)\n",
    "html = driver.execute_script(\"return document.documentElement.outerHTML\")\n",
    "page_selenium = bs(html, 'html.parser')\n",
    "\n",
    "erro_1 = 0\n",
    "erro_2 = 0\n",
    "\n",
    "try:\n",
    "    tam_ao_vivo = len(page_selenium.find_all('tbody')[1].find_all(class_='name'))\n",
    "    ao_vivo = page_selenium.find_all('tbody')[1].find_all(class_='name')\n",
    "except:\n",
    "    erro_1 = 1\n",
    "    \n",
    "try:\n",
    "    tam_a_seguir = len(page_selenium.find_all('tbody')[2].find_all(class_='name'))\n",
    "    a_seguir = page_selenium.find_all('tbody')[2].find_all(class_='name')\n",
    "except:\n",
    "    erro_2 = 1\n",
    "\n",
    "if erro_1 == 0:\n",
    "    print('Ao vivo\\n')\n",
    "    for i in range(tam_ao_vivo):    \n",
    "        print(ao_vivo[i].text)\n",
    "\n",
    "if erro_2 == 0:\n",
    "    print('\\nA seguir\\n')\n",
    "    for i in range(tam_a_seguir):\n",
    "        print(a_seguir[i].text)\n",
    "        \n",
    "driver.quit() # fecha o navegador que estava aberto e invisível"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preenchendo um campo e apertando no botão correspondente para enviar os dados digitados\n",
    "\n",
    "from selenium import webdriver\n",
    "\n",
    "url = 'https://www.google.com.br/'\n",
    "driver = webdriver.Firefox()\n",
    "driver.get(url)\n",
    "\n",
    "driver.find_element_by_css_selector('.gLFyf').send_keys('Digitado pelo Robô de André')\n",
    "driver.find_element_by_css_selector('.FPdoLc > center:nth-child(1) > input:nth-child(1)').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preenchendo um campo e apertando enter para enviar os dados digitados\n",
    "\n",
    "from selenium import webdriver\n",
    "\n",
    "url = 'https://www.google.com.br/'\n",
    "driver = webdriver.Firefox()\n",
    "driver.get(url)\n",
    "\n",
    "elemento = driver.find_element_by_css_selector('.gLFyf')\n",
    "elemento.send_keys('Digitado pelo Robô de André criado em Python!')\n",
    "elemento.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# robô que loga no facebook com clique no botão de login\n",
    "\n",
    "from selenium import webdriver\n",
    "\n",
    "driver = webdriver.Firefox()\n",
    "driver.get('https://www.facebook.com')\n",
    "\n",
    "driver.find_element_by_css_selector('#email').send_keys('anddre_oliveira@hotmail.com')\n",
    "driver.find_element_by_css_selector('#pass').send_keys('andrews123')\n",
    "\n",
    "# o botão para clicar poderia ter sido referenciado também pelo id ou outra coisa\n",
    "# mas para referenciar por classe, só usamos o nome antes ou depois do espaço entre as palavras\n",
    "# caso o nome da classe tenha mais de um nome\n",
    "driver.find_element_by_class_name('uiButton').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# robô que loga no facebook apertando enter na hora de logar\n",
    "\n",
    "from selenium import webdriver\n",
    "\n",
    "driver = webdriver.Firefox()\n",
    "driver.get('https://www.facebook.com')\n",
    "\n",
    "elemento = driver.find_element_by_css_selector('#email')\n",
    "elemento.send_keys('anddre_oliveira@hotmail.com')\n",
    "elemento = driver.find_element_by_css_selector('#pass')\n",
    "elemento.send_keys('andrews123')\n",
    "elemento.submit()\n",
    "\n",
    "# no lugar do comando acima tbm poderíamos fazer:\n",
    "# elemento.send_keys(Keys.RETURN) => RETURN corresponde à tecla enter. O último \"K\" aqui é maiúsculo\n",
    "# mas teríamos que dar o seguinte import primeiro:\n",
    "# from selenium.webdriver.common.keys import Keys (esse último \"Keys\" é com \"K\" maiúsculo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preenchendo um campo e apertando backspace (espaço)\n",
    "# usei a documentação do webdriver firefox selenium em python \n",
    "# para pegar comandos de tecla\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "url = 'https://10fastfingers.com/advanced-typing-test/portuguese'\n",
    "driver = webdriver.Firefox()\n",
    "driver.get(url)\n",
    "login = driver.find_element_by_css_selector('ul.nav:nth-child(5) > li:nth-child(2) > a:nth-child(1)').click()\n",
    "login = driver.find_element_by_css_selector('#UserEmail')\n",
    "login.send_keys('aoliveira371@gmail.com')\n",
    "login = driver.find_element_by_css_selector('#UserPassword')\n",
    "login.send_keys('091225')\n",
    "login.send_keys(Keys.RETURN)\n",
    "time.sleep(5)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        elemento = driver.find_element_by_css_selector('#inputfield')\n",
    "        palavra = driver.find_element_by_css_selector('.highlight').text\n",
    "        elemento.send_keys(palavra)\n",
    "        elemento.send_keys(Keys.SPACE)\n",
    "    except:\n",
    "        print('Terminou...')\n",
    "        break\n",
    "print('fim do while')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Campeonato Brasileiro Série A\n",
      "\n",
      "Botafogo VS AtléticoPR\n",
      "\n",
      "0 x 1 -> 15.97%\n",
      "0 x 2 -> 12.25%\n",
      "1 x 1 -> 11.64%\n",
      "0 x 0 -> 10.42%\n",
      "1 x 2 -> 8.92%\n",
      "1 x 0 -> 7.59%\n",
      "0 x 3 -> 6.26%\n",
      "1 x 3 -> 4.56%\n",
      "2 x 1 -> 4.24%\n",
      "2 x 2 -> 3.25%\n",
      "\n",
      "prob. de vitória casa => 17.70%\n",
      "prob. de empate: 25.74%\n",
      "prob. de vitória visitante => 56.57%\n",
      "\n",
      "prob. dupla chance casa => 43.43%\n",
      "prob. dupla chance visitante => 82.30%\n",
      "\n",
      "prob. empate anula casa => 23.83%\n",
      "prob. empate anula visitante: => 76.17%\n",
      "\n",
      "prob. under 0.5 => 10.42%\n",
      "prob. over 0.5 => 89.58%\n",
      "\n",
      "prob. under 1.5 => 33.98%\n",
      "prob. over 1.5 => 66.02%\n",
      "\n",
      "prob. under 2.5 => 60.63%\n",
      "prob. over 2.5 => 39.37%\n",
      "\n",
      "prob. under 3.5 => 80.71%\n",
      "prob. over 3.5 => 19.29%\n",
      "\n",
      "prob. ambas marcam sim => 40.56%\n",
      "prob. ambas marcam não => 59.44%\n"
     ]
    }
   ],
   "source": [
    "# navegador invisível -> jogos da rodada brasileirão série A\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "geckodriver = '/home/andre/Downloads/geckodriver'\n",
    "driver = webdriver.FirefoxOptions()\n",
    "driver.add_argument('-headless')\n",
    "driver = webdriver.Firefox(executable_path=geckodriver, options=driver)\n",
    "driver.get('https://www.academiadasapostasbrasil.com/stats/competition/brasil-stats/26')\n",
    "time.sleep(2)\n",
    "\n",
    "html = driver.execute_script(\"return document.documentElement.outerHTML\")\n",
    "page = bs(html, 'html.parser')\n",
    "\n",
    "# jogos = page.find_all(class_='even')[1].find_all(target='_self')[2].text\n",
    "\n",
    "# as aspas simples como primeiro argumento do find_all \n",
    "# indica que quero um elemento, como uma classe por exemplo, mas não quero especificar de que tag\n",
    "tam1 = len(page.find('table',{'class':'competition-rounds'}).find_all('',{'class':'even'}))\n",
    "tam2 = len(page.find('table',{'class':'competition-rounds'}).find_all('',{'class':'odd'}))\n",
    "tam = tam1 + tam2\n",
    "jogo = [0] * tam\n",
    "tam_link_vs = [0] * tam\n",
    "cont1 = 0\n",
    "cont2 = 1\n",
    "\n",
    "for i in range(tam1):\n",
    "    tam_link_vs[cont1] = len(page.find_all('',{'class':'even'})[i].find_all(target='_self'))\n",
    "    cont1 += 2\n",
    "for i in range(tam2):\n",
    "    tam_link_vs[cont2] = len(page.find_all('',{'class':'odd'})[i].find_all(target='_self'))\n",
    "    cont2 += 2\n",
    "\n",
    "cont1 = 0\n",
    "cont2 = 1\n",
    "\n",
    "for i in range(tam1):\n",
    "    for j in range(tam_link_vs[cont1]):\n",
    "        aux = page.find_all('',{'class':'even'})[i].find_all('a')[j].text\n",
    "        aux = aux.strip()\n",
    "        if aux == 'vs':\n",
    "            jogo[cont1] = page.find_all('',{'class':'even'})[i].find_all('a')[j].get('href')\n",
    "    cont1 += 2\n",
    "\n",
    "for i in range(tam2):\n",
    "    for j in range(tam_link_vs[cont2]):\n",
    "        aux = page.find_all('',{'class':'odd'})[i].find_all('a')[j].text\n",
    "        aux = aux.strip()\n",
    "        if aux == 'vs':\n",
    "            jogo[cont2] = page.find_all('',{'class':'odd'})[i].find_all('a')[j].get('href')\n",
    "    cont2 += 2\n",
    "\n",
    "# Análise do jogo 1 da rodada do brasileirão\n",
    "driver.get(jogo[6])\n",
    "time.sleep(2)\n",
    "html = driver.execute_script(\"return document.documentElement.outerHTML\")\n",
    "page = bs(html, 'html.parser')\n",
    "\n",
    "equipes = page.find_all('span',{'class':'stats-title'})[0].text.strip().replace(\" \", \"\")\n",
    "equipes = equipes.replace(\"\\n\", \"\")\n",
    "equipes = equipes.replace(\"VS\", \" VS \")\n",
    "\n",
    "mgf_tcasa = float(page.find_all('table',{'class':'stat-seqs stat-half-padding'})[2].find_all('tr',{'class':'even'})[0].find('',{'class':'highlight-home'}).text) \n",
    "mgs_tcasa = float(page.find_all('table',{'class':'stat-seqs stat-half-padding'})[2].find_all('tr',{'class':'even'})[1].find('',{'class':'highlight-home'}).text)\n",
    "mgf_tfora = float(page.find_all('table',{'class':'stat-seqs stat-half-padding'})[3].find_all('tr',{'class':'even'})[0].find('',{'class':'highlight-away'}).text)\n",
    "mgs_tfora = float(page.find_all('table',{'class':'stat-seqs stat-half-padding'})[3].find_all('tr',{'class':'even'})[1].find('',{'class':'highlight-away'}).text)\n",
    "mgf_ccasa = float(page.find('',{'class':'boxed stats_resume'}).find_all('li')[9].find(class_='values').text.strip())\n",
    "mgs_ccasa = float(page.find('',{'class':'boxed stats_resume'}).find_all('li')[10].find(class_='values').text.strip())\n",
    "mgf_cfora = float(page.find('',{'class':'boxed stats_resume'}).find_all('li')[10].find(class_='values').text.strip()) \n",
    "mgs_cfora = float(page.find('',{'class':'boxed stats_resume'}).find_all('li')[9].find(class_='values').text.strip())\n",
    "\n",
    "media_getc = mgf_tcasa / mgf_ccasa * mgs_tfora / mgs_cfora * mgf_ccasa\n",
    "media_getf = mgf_tfora / mgf_cfora * mgs_tcasa / mgs_ccasa * mgf_cfora\n",
    "\n",
    "# p/ prob. do número de gols\n",
    "probf_casa = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "probf_fora = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "probs_casa = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "probs_fora = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "# p/ prob. de vitória, empate e derrota\n",
    "probv_casa = 0\n",
    "probv_fora = 0\n",
    "prob_empate = 0\n",
    "\n",
    "# p/ prob. dupla chance\n",
    "dupla_casa = 0\n",
    "dupla_fora = 0\n",
    "\n",
    "# p/ prob. empate anula\n",
    "emp_ac = 0\n",
    "emp_af = 0\n",
    "\n",
    "# p/ prob. under e over\n",
    "under_05 = 0\n",
    "over_05 = 0\n",
    "under_15 = 0\n",
    "over_15 = 0\n",
    "under_25 = 0\n",
    "over_25 = 0\n",
    "under_35 = 0\n",
    "over_35 = 0\n",
    "\n",
    "# p/ prob. ambas marcam\n",
    "ambas_sim = 0\n",
    "ambas_nao = 0\n",
    "\n",
    "prob_placar = np.zeros((11,11), dtype=np.float64)\n",
    "placar_ordenado = []\n",
    "pos_placar_ordenado = []\n",
    "posicao = 0\n",
    "cont = 0\n",
    "\n",
    "# prob. de gols do time da casa e fora\n",
    "for i in range(11):\n",
    "    probf_casa[i] = (math.exp(-media_getc)*media_getc**i)/math.factorial(i)\n",
    "    probf_fora[i] = (math.exp(-media_getf)*media_getf**i)/math.factorial(i)\n",
    "\n",
    "# prob. de placares do jogo; prob. de 1x2; prob. de under e over\n",
    "# i -> num de gols do time da casa; j -> num de gols do time de fora\n",
    "for i in range(11):\n",
    "    for j in range(11):\n",
    "        # prob. de 1x2\n",
    "        if i > j:\n",
    "            probv_casa += probf_casa[i] * probf_fora[j] * 100\n",
    "        elif j > i:\n",
    "            probv_fora += probf_casa[i] * probf_fora[j] * 100\n",
    "        else: \n",
    "            prob_empate += probf_casa[i] * probf_fora[j] * 100\n",
    "        \n",
    "        # prob. de under e over\n",
    "        # under/over 0.5\n",
    "        if i + j <= 0:\n",
    "            under_05 += probf_casa[i] * probf_fora[j] * 100\n",
    "        \n",
    "        # under/over 1.5\n",
    "        if i + j <= 1:\n",
    "            under_15 += probf_casa[i] * probf_fora[j] * 100\n",
    "            \n",
    "        # under/over 2.5\n",
    "        if i + j <= 2:\n",
    "            under_25 += probf_casa[i] * probf_fora[j] * 100\n",
    "            \n",
    "        # under/over 3.5\n",
    "        if i + j <= 3:\n",
    "            under_35 += probf_casa[i] * probf_fora[j] * 100\n",
    "            \n",
    "        # prob. ambas marcam\n",
    "        if (i > 0) and (j > 0):\n",
    "            ambas_sim += probf_casa[i] * probf_fora[j] * 100\n",
    "         \n",
    "        # prob. de placar exato\n",
    "        prob_placar[i][j] = probf_casa[i] * probf_fora[j] * 100\n",
    "        placar_ordenado.append(prob_placar[i][j])\n",
    "        pos_placar_ordenado.append(placar_ordenado[cont])\n",
    "        cont += 1\n",
    "        # print(f'{i} x {j} -> {prob_placar[i][j]:.2f}%')\n",
    "\n",
    "# prob. dupla chance\n",
    "dupla_casa = (probv_casa + prob_empate) \n",
    "dupla_fora = (probv_fora + prob_empate)\n",
    "        \n",
    "# prob. empate anula\n",
    "emp_ac = probv_casa/(probv_casa + probv_fora) * 100\n",
    "emp_af = 100 - emp_ac\n",
    "\n",
    "# prob. over 0.5\n",
    "over_05 = 100 - under_05\n",
    "\n",
    "# prob. over 1.5\n",
    "over_15 = 100 - under_15\n",
    "\n",
    "# prob. over 2.5\n",
    "over_25 = 100 - under_25\n",
    "\n",
    "# prob. over 3.5\n",
    "over_35 = 100 - under_35\n",
    "\n",
    "# prob. ambas marcam não\n",
    "ambas_nao = 100 - ambas_sim\n",
    "        \n",
    "placar_ordenado.sort(reverse = True)\n",
    "\n",
    "print(f'Campeonato Brasileiro Série A\\n')\n",
    "print(f'{equipes}\\n')\n",
    "# for i in range(121): 121 é o máximo. Nesse range pode-se escolher quantos resultados corretos exibir\n",
    "for i in range(10):\n",
    "    posicao = pos_placar_ordenado.index(placar_ordenado[i])\n",
    "    \n",
    "    # Resultados Corretos\n",
    "    print(f'{int(posicao/11)} x {posicao%11} -> {placar_ordenado[i]:.2f}%')\n",
    "\n",
    "# 1x2\n",
    "print(f'\\nprob. de vitória casa => {probv_casa:.2f}%')\n",
    "print(f'prob. de empate: {prob_empate:.2f}%')\n",
    "print(f'prob. de vitória visitante => {probv_fora:.2f}%')\n",
    "\n",
    "# dupla chance\n",
    "print(f'\\nprob. dupla chance casa => {dupla_casa:.2f}%')\n",
    "print(f'prob. dupla chance visitante => {dupla_fora:.2f}%')\n",
    "\n",
    "# empate anula\n",
    "print(f'\\nprob. empate anula casa => {emp_ac:.2f}%')\n",
    "print(f'prob. empate anula visitante: => {emp_af:.2f}%')\n",
    "\n",
    "# under/over 0.5\n",
    "print(f'\\nprob. under 0.5 => {under_05:.2f}%')\n",
    "print(f'prob. over 0.5 => {over_05:.2f}%')\n",
    "\n",
    "# under/over 1.5\n",
    "print(f'\\nprob. under 1.5 => {under_15:.2f}%')\n",
    "print(f'prob. over 1.5 => {over_15:.2f}%')\n",
    "\n",
    "# under/over 2.5\n",
    "print(f'\\nprob. under 2.5 => {under_25:.2f}%')\n",
    "print(f'prob. over 2.5 => {over_25:.2f}%')\n",
    "\n",
    "# under/over 3.5\n",
    "print(f'\\nprob. under 3.5 => {under_35:.2f}%')\n",
    "print(f'prob. over 3.5 => {over_35:.2f}%')\n",
    "\n",
    "# ambas marcam\n",
    "print(f'\\nprob. ambas marcam sim => {ambas_sim:.2f}%')\n",
    "print(f'prob. ambas marcam não => {ambas_nao:.2f}%')\n",
    "\n",
    "driver.quit() # fecha o navegador que estava aberto porém invisível"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
